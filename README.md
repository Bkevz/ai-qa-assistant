# AI Q&A Assistant

A modern, secure, and well-documented full-stack web application that serves as an interactive AI Q&A assistant.

## ğŸ”§ Project Overview

This application allows users to ask questions via a clean, modern interface and receive answers from an AI language model. The application is built with a FastAPI backend and a Next.js frontend.

### Features

- Clean, modern UI with Tailwind CSS
- Real-time streaming responses from the AI
- Dark mode toggle
- Chat history saved in localStorage
- Responsive design

## ğŸ“ Project Structure

```
root/
â”œâ”€â”€ frontend/            # Next.js + TailwindCSS
â”‚   â”œâ”€â”€ pages/           # Next.js pages
â”‚   â”œâ”€â”€ components/      # React components
â”‚   â”‚   â”œâ”€â”€ QueryForm.tsx
â”‚   â”‚   â”œâ”€â”€ ResponseDisplay.tsx
â”‚   â”‚   â””â”€â”€ DarkModeToggle.tsx
â”‚   â”œâ”€â”€ styles/          # CSS styles
â”‚   â””â”€â”€ .env             # Frontend environment variables
â”‚
â”œâ”€â”€ backend/             # FastAPI app
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py      # FastAPI application entry point
â”‚   â”‚   â”œâ”€â”€ routes/      # API routes
â”‚   â”‚   â”œâ”€â”€ services/    # Business logic
â”‚   â”‚   â””â”€â”€ schemas/     # Pydantic models
â”‚   â”œâ”€â”€ .env             # Backend environment variables
â”‚   â””â”€â”€ requirements.txt # Python dependencies
```

## ğŸš€ Setup Instructions

### Backend Setup

1. Navigate to the backend directory:
   ```bash
   cd backend
   ```

2. Create a virtual environment:
   ```bash
   python -m venv venv
   ```

3. Activate the virtual environment:
   - Windows:
     ```bash
     .\venv\Scripts\activate
     ```
   - macOS/Linux:
     ```bash
     source venv/bin/activate
     ```

4. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

5. Create a `.env` file based on `.env.example` and add your OpenAI API key:
   ```
   OPENAI_API_KEY=your_openai_api_key_here
   ```

6. Run the backend server:
   ```bash
   uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
   ```

### Frontend Setup

1. Navigate to the frontend directory:
   ```bash
   cd frontend
   ```

2. Install dependencies:
   ```bash
   npm install
   ```

3. Create a `.env.local` file with the backend URL:
   ```
   NEXT_PUBLIC_API_URL=http://localhost:8000
   ```

4. Run the development server:
   ```bash
   npm run dev
   ```

5. Open [http://localhost:3000](http://localhost:3000) in your browser.

## ğŸ“ API Documentation

Once the backend is running, you can access the API documentation at:
- Swagger UI: [http://localhost:8000/docs](http://localhost:8000/docs)
- ReDoc: [http://localhost:8000/redoc](http://localhost:8000/redoc)

## ğŸ” Environment Variables

### Backend (.env)

| Variable | Description | Required |
|----------|-------------|----------|
| OPENAI_API_KEY | Your OpenAI API key | Yes |
| HOST | Host to run the server on | No (default: 0.0.0.0) |
| PORT | Port to run the server on | No (default: 8000) |

### Frontend (.env.local)

| Variable | Description | Required |
|----------|-------------|----------|
| NEXT_PUBLIC_API_URL | URL of the backend API | Yes |

## ğŸ“‹ Example Prompts

Here are some example prompts to try with the AI assistant:

- "What is the capital of France?"
- "Explain quantum computing in simple terms."
- "Write a short poem about technology."
- "What are the benefits of exercise?"
- "How does blockchain technology work?"

## ğŸ§ª Optional Features

- **Dark Mode**: Toggle between light and dark themes with the sun/moon icon in the header.
- **Streaming Responses**: See the AI's response in real-time as it's being generated.
- **Chat History**: Your conversation history is saved in your browser's localStorage.
